{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C12N7M4mRXq",
        "outputId": "7c3988f9-3385-4559-afdf-262081676702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: True, device name: Tesla T4\n",
            "Running at: 2025-10-14T16:43:39.607060 UTC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2279429140.py:43: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  print(f\"Running at: {datetime.utcnow().isoformat()} UTC\")\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 1ï¸âƒ£ IMPORTS\n",
        "# =========================\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "from datetime import datetime\n",
        "\n",
        "# sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score, classification_report, confusion_matrix\n",
        "\n",
        "# Colab download helper (works only in Colab)\n",
        "try:\n",
        "    from google.colab import files as colab_files\n",
        "    _IN_COLAB = True\n",
        "except Exception:\n",
        "    _IN_COLAB = False\n",
        "\n",
        "# for reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# GPU detection (for user info only)\n",
        "try:\n",
        "    import torch\n",
        "    gpu_available = torch.cuda.is_available()\n",
        "    gpu_name = torch.cuda.get_device_name(0) if gpu_available else \"No GPU\"\n",
        "except Exception:\n",
        "    gpu_available = False\n",
        "    gpu_name = \"torch not installed / unavailable\"\n",
        "\n",
        "print(f\"GPU available: {gpu_available}, device name: {gpu_name}\")\n",
        "print(f\"Running at: {datetime.utcnow().isoformat()} UTC\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2ï¸âƒ£ READ DATASET\n",
        "# =========================\n",
        "# Replace path with your Colab-mounted drive path or upload the csv to Colab working dir.\n",
        "DATA_PATH = \"HEAR_Dataset.csv\"  # change if needed\n",
        "\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    raise FileNotFoundError(f\"{DATA_PATH} not found. Upload it to the runtime or update DATA_PATH.\")\n",
        "\n",
        "df = pd.read_csv(DATA_PATH, encoding='utf-8')\n",
        "# Basic sanity check\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "# Expected columns: \"Review Text\", \"Pricing\", \"Appointments\", \"Medical Staff\", \"Customer Service\", \"Emergency Services\"\n",
        "aspect_names = [\"Pricing\", \"Appointments\", \"Medical Staff\", \"Customer Service\", \"Emergency Services\"]\n",
        "for a in aspect_names:\n",
        "    if a not in df.columns:\n",
        "        raise ValueError(f\"Expected column '{a}' not found in dataset.\")\n",
        "\n",
        "# Convert Review Text to string and strip\n",
        "df[\"Review Text\"] = df[\"Review Text\"].astype(str).str.strip()\n",
        "\n",
        "# Optional: quick label dtype check\n",
        "print(\"Label sample (first 5 rows):\")\n",
        "display(df[[\"Review Text\"] + aspect_names].head())\n",
        "\n",
        "# =========================\n",
        "# 3ï¸âƒ£ SPLIT TRAIN / TEST\n",
        "# =========================\n",
        "texts = df[\"Review Text\"].tolist()\n",
        "labels = df[aspect_names].values  # shape (n_samples, 5)\n",
        "\n",
        "X_train_texts, X_test_texts, y_train, y_test = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=RANDOM_STATE, stratify=None\n",
        ")\n",
        "print(f\"Train size: {len(X_train_texts)}, Test size: {len(X_test_texts)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "k5Gm0HUZmbhn",
        "outputId": "40f2832e-b878-465a-d500-bc2d7f5846c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (23004, 6)\n",
            "Columns: ['Review Text', 'Pricing', 'Appointments', 'Medical Staff', 'Customer Service', 'Emergency Services']\n",
            "Label sample (first 5 rows):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                         Review Text  Pricing  Appointments  \\\n",
              "0  Ù…Ø³ØªØ´ÙÙ‰ ÙƒØ¨ÙŠØ± Ø§Ø´ÙƒØ± Ø§Ù„Ø¯ÙƒØªÙˆØ±Ù‡ Ù‡ÙŠØ¨Ø§Øª Ø§Ù„ØµØ¯ÙŠÙ‚ÙŠ ØµØ§Ø­Ø¨Ù‡ ...        3             3   \n",
              "1  Ø´ÙƒØ±Ø§ Ù„Ù‡Ù…  ÙØ±Ø¯Ø§ ÙØ±Ø¯Ø§ â€¦.Ø¥Ø¨ØªØ¯Ø§Ø¡Ù‹ Ù…Ù† Ø§Ù„Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø«Ù… ...        3             3   \n",
              "2  Ø´ÙƒØ± Ùˆ ØªÙ‚Ø¯ÙŠØ± Ù„ÙƒÙŠ Ø¯ÙƒØªÙˆØ±Ø© ÙˆÙ„Ø§Ø¡ Ø¹Ø§Ù…Ø± Ø¨Ø§Ù„Ù†Ø³Ø§Ø¡ Ùˆ Ø§Ù„Ùˆ...        3             3   \n",
              "3  Ù…Ø³ØªØ´ÙÙ‰ ÙƒØ¨ÙŠØ± ÙˆÙ…Ø±ØªØ¨ ÙˆÙÙŠÙ‡ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ®ØµØµØ§Øª ÙˆÙƒÙØ§Ø¡Ø§Øª Ø¹...        1             3   \n",
              "4  Ø³ÙŠØ¡ Ø«Ù…. Ø³ÙŠØ¡ Ø«Ù… Ø³ÙŠØ¡ Ø«Ù… Ø³ÙŠØ¡\\nÙ…Ø«Ù„ Ù…Ø§Ø§Ù†ØªÙ… Ø´Ø§ÙŠÙÙŠÙ† Ù...        0             3   \n",
              "\n",
              "   Medical Staff  Customer Service  Emergency Services  \n",
              "0              1                 1                   3  \n",
              "1              1                 1                   3  \n",
              "2              1                 3                   3  \n",
              "3              1                 1                   3  \n",
              "4              0                 0                   3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f775d164-6160-4567-b4c2-f42ca6358556\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Pricing</th>\n",
              "      <th>Appointments</th>\n",
              "      <th>Medical Staff</th>\n",
              "      <th>Customer Service</th>\n",
              "      <th>Emergency Services</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ù…Ø³ØªØ´ÙÙ‰ ÙƒØ¨ÙŠØ± Ø§Ø´ÙƒØ± Ø§Ù„Ø¯ÙƒØªÙˆØ±Ù‡ Ù‡ÙŠØ¨Ø§Øª Ø§Ù„ØµØ¯ÙŠÙ‚ÙŠ ØµØ§Ø­Ø¨Ù‡ ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ø´ÙƒØ±Ø§ Ù„Ù‡Ù…  ÙØ±Ø¯Ø§ ÙØ±Ø¯Ø§ â€¦.Ø¥Ø¨ØªØ¯Ø§Ø¡Ù‹ Ù…Ù† Ø§Ù„Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø«Ù… ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ø´ÙƒØ± Ùˆ ØªÙ‚Ø¯ÙŠØ± Ù„ÙƒÙŠ Ø¯ÙƒØªÙˆØ±Ø© ÙˆÙ„Ø§Ø¡ Ø¹Ø§Ù…Ø± Ø¨Ø§Ù„Ù†Ø³Ø§Ø¡ Ùˆ Ø§Ù„Ùˆ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ù…Ø³ØªØ´ÙÙ‰ ÙƒØ¨ÙŠØ± ÙˆÙ…Ø±ØªØ¨ ÙˆÙÙŠÙ‡ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ®ØµØµØ§Øª ÙˆÙƒÙØ§Ø¡Ø§Øª Ø¹...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ø³ÙŠØ¡ Ø«Ù…. Ø³ÙŠØ¡ Ø«Ù… Ø³ÙŠØ¡ Ø«Ù… Ø³ÙŠØ¡\\nÙ…Ø«Ù„ Ù…Ø§Ø§Ù†ØªÙ… Ø´Ø§ÙŠÙÙŠÙ† Ù...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f775d164-6160-4567-b4c2-f42ca6358556')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f775d164-6160-4567-b4c2-f42ca6358556 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f775d164-6160-4567-b4c2-f42ca6358556');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c284f9f1-878e-4666-b7a0-f7e57f80696b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c284f9f1-878e-4666-b7a0-f7e57f80696b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c284f9f1-878e-4666-b7a0-f7e57f80696b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(f\\\"Train size: {len(X_train_texts)}, Test size: {len(X_test_texts)}\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Review Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0634\\u0643\\u0631\\u0627 \\u0644\\u0647\\u0645  \\u0641\\u0631\\u062f\\u0627 \\u0641\\u0631\\u062f\\u0627 \\u2026.\\u0625\\u0628\\u062a\\u062f\\u0627\\u0621\\u064b \\u0645\\u0646 \\u0627\\u0644\\u0627\\u0633\\u062a\\u0642\\u0628\\u0627\\u0644 \\u062b\\u0645 \\u0627\\u0644\\u0637\\u0627\\u0642\\u0645 \\u0627\\u0644\\u0637\\u0628\\u064a \\u060c \\u0645\\u0646 \\u062a\\u0645\\u0631\\u064a\\u0636 \\u0648\\u0627\\u0637\\u0628\\u0627\\u0621 \\u060c\\u060c \\u0645\\u062d\\u062a\\u0631\\u0645\\u064a\\u0646 \\u0648\\u0628\\u0634\\u0648\\u0634\\u064a\\u0646 \\u060c\\u060c\\u0627\\u0633\\u0644\\u0648\\u0628 \\u0627\\u062d\\u062a\\u0631\\u0627\\u0641\\u064a \\u0641\\u064a \\u0637\\u0631\\u064a\\u0642\\u0629 \\u0637\\u0645\\u0626\\u0646\\u0629 \\u0627\\u0644\\u0645\\u0631\\u064a\\u0636 ..\\u0648\\u0627\\u064a\\u0636\\u0627 \\u0627\\u0644\\u0646\\u0638\\u0627\\u0641\\u0647 \\u0645\\u0644\\u062d\\u0648\\u0638\\u0629 \\u0641\\u064a \\u062f\\u0648\\u0631\\u0627\\u062a \\u0627\\u0644\\u0645\\u064a\\u0627\\u0647 \\u0648\\u0627\\u0644\\u063a\\u0631\\u0641 \\u0628\\u0634\\u0643\\u0644 \\u0645\\u0633\\u062a\\u0645\\u0631  \\u0634\\u0643\\u0631\\u0627 \\u0644\\u0647\\u0645\",\n          \"\\u0633\\u064a\\u0621 \\u062b\\u0645. \\u0633\\u064a\\u0621 \\u062b\\u0645 \\u0633\\u064a\\u0621 \\u062b\\u0645 \\u0633\\u064a\\u0621\\n\\u0645\\u062b\\u0644 \\u0645\\u0627\\u0627\\u0646\\u062a\\u0645 \\u0634\\u0627\\u064a\\u0641\\u064a\\u0646 \\u0641\\u064a \\u0627\\u063a\\u0644\\u0628 \\u0627\\u0644\\u062a\\u0639\\u0644\\u064a\\u0642\\u0627\\u062a. \\u064a\\u0627\\u0645\\u0633\\u0627\\u0634\\u0641\\u0649 \\u0627\\u0644\\u062d\\u0645\\u0627\\u062f\\u064a \\u0644\\u0627\\u0632\\u0645 \\u062a\\u062d\\u0637\\u0648\\u0646 \\u0627\\u062f\\u0627\\u0631\\u0629 \\u0648\\u0631\\u0642\\u0627\\u0628\\u0629 \\u0635\\u0627\\u0631\\u0645\\u0629 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0645\\u0648\\u0638\\u0641\\u064a\\u0646 \\u0641\\u064a \\u0645\\u0643\\u062a\\u0628 \\u0627\\u0644\\u062a\\u0623\\u0645\\u064a\\u0646 \\u0648\\u0627\\u0644\\u0627\\u0633\\u062a\\u0642\\u0628\\u0627\\u0644 \\u0644\\u0623\\u0646\\u0647\\u0645 \\u0641\\u0627\\u0634\\u0644\\u064a\\u0646 \\u062f\\u0631\\u062c\\u0629 \\u0627\\u0648\\u0644\\u0649 \\u060c \\u0627\\u0644\\u0645\\u0631\\u064a\\u0636 \\u064a\\u0632\\u064a\\u062f \\u0645\\u0631\\u0636\\u0647 \\u0645\\u0631\\u0636 \\u0645\\u0646 \\u0645\\u0645\\u0627\\u0637\\u0644\\u0629 \\u0631\\u0641\\u0639 \\u0627\\u0644\\u062a\\u0627\\u0645\\u064a\\u0646 \\u0648\\u0627\\u0644\\u062a\\u062d\\u0627\\u0644\\u064a\\u0644 \\u0627\\u0644\\u0644\\u064a \\u062a\\u0637\\u0644\\u0628 \\u0628\\u062f\\u0648\\u0646 \\u0627\\u064a \\u0647\\u062f\\u0641 \\u062b\\u0645 \\u064a\\u0638\\u0637\\u0631 \\u0627\\u0644\\u0645\\u0631\\u064a\\u0636 \\u064a\\u0647\\u0631\\u0628 \\u0645\\u0646 \\u0627\\u0644\\u0645\\u0633\\u062a\\u0634\\u0641\\u0649 \\u0645\\u063a\\u0628\\u0648\\u0646 \\u0644\\u0623\\u0646\\u0647 \\u0645\\u0627\\u062d\\u0635\\u0644 \\u062d\\u0627\\u062c\\u062a\\u0647 \\u0628\\u0639\\u062f \\u0645\\u0627\\u0627\\u0633\\u062a\\u0646\\u0632\\u0641\\u0648\\u0627 \\u0627\\u0645\\u0648\\u0627\\u0644\\u0647\",\n          \"\\u0634\\u0643\\u0631 \\u0648 \\u062a\\u0642\\u062f\\u064a\\u0631 \\u0644\\u0643\\u064a \\u062f\\u0643\\u062a\\u0648\\u0631\\u0629 \\u0648\\u0644\\u0627\\u0621 \\u0639\\u0627\\u0645\\u0631 \\u0628\\u0627\\u0644\\u0646\\u0633\\u0627\\u0621 \\u0648 \\u0627\\u0644\\u0648\\u0644\\u0627\\u062f\\u0629 \\u0639\\u0644\\u0649 \\u062c\\u0647\\u0648\\u062f\\u0643 \\u0627\\u0644\\u0645\\u0628\\u0630\\u0648\\u0644\\u0629 \\u0648 \\u0627\\u062e\\u0644\\u0627\\u0642\\u0643 \\u0627\\u0644\\u0646\\u0628\\u064a\\u0644\\u0629 \\u0648 \\u062c\\u0632\\u0627\\u0643 \\u0627\\u0644\\u0644\\u0647 \\u0639\\u0646\\u0627 \\u062e\\u064a\\u0631 \\u0627\\u0644\\u062c\\u0632\\u0627\\u0621.\\n\\n\\u2764\\ufe0f\\u2764\\ufe0f\\ud83d\\udc96\\u2764\\ufe0f\\u2764\\ufe0f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pricing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Appointments\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Medical Staff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Customer Service\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Emergency Services\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 18403, Test size: 4601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4ï¸âƒ£ TF-IDF VECTORIZATION (shared encoder)\n",
        "# =========================\n",
        "# Simple Arabic normalization function\n",
        "import re\n",
        "def normalize_arabic(text):\n",
        "    text = str(text)\n",
        "    # remove tashkeel\n",
        "    text = re.sub(r'[\\u0617-\\u061A\\u064B-\\u0652]', '', text)\n",
        "    # normalize alef variants\n",
        "    text = re.sub(r'[Ø¥Ø£Ù±Ø¢Ø§]', 'Ø§', text)\n",
        "    # normalize ya\n",
        "    text = re.sub(r'[ÙŠÙ‰]', 'ÙŠ', text)\n",
        "    # normalize ta marbuta\n",
        "    text = re.sub(r'Ø©', 'Ù‡', text)\n",
        "    # remove non-Arabic letters and digits optionally (keep space and Arabic letters and basic punctuation)\n",
        "    text = re.sub(r'[^\\u0600-\\u06FF\\s\\.,!?Ø›ØŒ\\-]', '', text)\n",
        "    # collapse whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Apply normalization (fast)\n",
        "X_train_texts = [normalize_arabic(t) for t in X_train_texts]\n",
        "X_test_texts  = [normalize_arabic(t) for t in X_test_texts]\n",
        "\n",
        "# TF-IDF vectorizer config â€” tuned for Arabic\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=20000,\n",
        "    ngram_range=(1,2),\n",
        "    analyzer='word',\n",
        "    token_pattern=r'(?u)\\b\\w+\\b',\n",
        "    lowercase=False  # we've normalized; Arabic lowercase not relevant\n",
        ")\n",
        "\n",
        "print(\"Fitting TF-IDF vectorizer on training texts...\")\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train_texts)\n",
        "X_test_tfidf  = vectorizer.transform(X_test_texts)\n",
        "print(\"TF-IDF shapes:\", X_train_tfidf.shape, X_test_tfidf.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efONP0xDmdg_",
        "outputId": "09069fff-c5d4-43fd-adf0-2a29f0649f2e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting TF-IDF vectorizer on training texts...\n",
            "TF-IDF shapes: (18403, 20000) (4601, 20000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5ï¸âƒ£ LABEL PREPARATION (no tensors)\n",
        "# =========================\n",
        "# Labels are already numeric (0,1,2,3). Check class distribution per aspect\n",
        "for i, aspect in enumerate(aspect_names):\n",
        "    unique, counts = np.unique(y_train[:, i], return_counts=True)\n",
        "    print(f\"{aspect} train distribution: {dict(zip(unique, counts))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5wO3G-MmgCW",
        "outputId": "9c896230-1078-49ce-f43a-238367755472"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pricing train distribution: {np.int64(0): np.int64(1409), np.int64(1): np.int64(77), np.int64(2): np.int64(103), np.int64(3): np.int64(16814)}\n",
            "Appointments train distribution: {np.int64(0): np.int64(2027), np.int64(1): np.int64(321), np.int64(2): np.int64(118), np.int64(3): np.int64(15937)}\n",
            "Medical Staff train distribution: {np.int64(0): np.int64(3044), np.int64(1): np.int64(6038), np.int64(2): np.int64(432), np.int64(3): np.int64(8889)}\n",
            "Customer Service train distribution: {np.int64(0): np.int64(5865), np.int64(1): np.int64(5717), np.int64(2): np.int64(154), np.int64(3): np.int64(6667)}\n",
            "Emergency Services train distribution: {np.int64(0): np.int64(1265), np.int64(1): np.int64(320), np.int64(2): np.int64(33), np.int64(3): np.int64(16785)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7ï¸âƒ£ MODEL DEFINITION (MultiOutputClassifier)\n",
        "# =========================\n",
        "# We'll create a LogisticRegression per aspect, with class weights computed per aspect\n",
        "estimators = []\n",
        "from sklearn.base import clone\n",
        "\n",
        "base_estimator = LogisticRegression(\n",
        "    solver='saga',          # saga for large datasets and supports l1/l2\n",
        "    multi_class='multinomial',\n",
        "    max_iter=2000,\n",
        "    n_jobs=-1,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Compute class weights per aspect and create custom estimators with those weights\n",
        "estimators_per_aspect = []\n",
        "for i, aspect in enumerate(aspect_names):\n",
        "    y_col = y_train[:, i]\n",
        "    classes = np.unique(y_col)\n",
        "    # compute_class_weight expects classes array\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_col)\n",
        "    # map to dict\n",
        "    cw_dict = {c: w for c, w in zip(classes, class_weights)}\n",
        "    # create estimator with these weights\n",
        "    est = LogisticRegression(\n",
        "        solver='saga',\n",
        "        multi_class='multinomial',\n",
        "        max_iter=2000,\n",
        "        class_weight=cw_dict,\n",
        "        n_jobs=-1,\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "    estimators_per_aspect.append(est)\n",
        "\n",
        "# MultiOutputClassifier with LogisticRegression base; sklearn will clone the base estimator per output.\n",
        "# We will pass a LogisticRegression that does not have class_weight, but then replace internal estimators manually after fit.\n",
        "multi_clf = MultiOutputClassifier(base_estimator, n_jobs=-1)"
      ],
      "metadata": {
        "id": "85GilnC4mh3f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8ï¸âƒ£ TRAINING SETUP\n",
        "# =========================\n",
        "print(\"Training MultiOutputClassifier (this may take a short while)...\")\n",
        "multi_clf.fit(X_train_tfidf, y_train)\n",
        "print(\"Initial training done.\")\n",
        "\n",
        "# Replace each estimator with a class-weighted retrained estimator for best imbalance handling:\n",
        "# Alternatively, fit separate estimators manually if you prefer more control.\n",
        "print(\"Refitting individual estimators with computed class weights per aspect for better handling of imbalance...\")\n",
        "for i, est in enumerate(estimators_per_aspect):\n",
        "    print(f\"  Fitting estimator for aspect: {aspect_names[i]}\")\n",
        "    est.fit(X_train_tfidf, y_train[:, i])\n",
        "    multi_clf.estimators_[i] = est\n",
        "print(\"All aspect estimators refitted.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQSUCxlDmj5v",
        "outputId": "7dc0aafa-80d0-4bd0-daaa-e1a5591b2c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MultiOutputClassifier (this may take a short while)...\n",
            "Initial training done.\n",
            "Refitting individual estimators with computed class weights per aspect for better handling of imbalance...\n",
            "  Fitting estimator for aspect: Pricing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Fitting estimator for aspect: Appointments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Fitting estimator for aspect: Medical Staff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Fitting estimator for aspect: Customer Service\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”Ÿ SAVING THE MODEL (vectorizer + multioutput classifier + metadata)\n",
        "# =========================\n",
        "save_dir = \"saved_model_tfidf\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "model_path = os.path.join(save_dir, \"multioutput_model.joblib\")\n",
        "vect_path  = os.path.join(save_dir, \"vectorizer.joblib\")\n",
        "meta_path  = os.path.join(save_dir, \"metadata.txt\")\n",
        "\n",
        "joblib.dump(multi_clf, model_path)\n",
        "joblib.dump(vectorizer, vect_path)\n",
        "\n",
        "with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"TF-IDF MultiOutput model\\n\")\n",
        "    f.write(f\"Saved at: {datetime.utcnow().isoformat()} UTC\\n\")\n",
        "    f.write(f\"Aspect names: {aspect_names}\\n\")\n",
        "    f.write(f\"Vectorizer max_features: {vectorizer.max_features}\\n\")\n",
        "\n",
        "# Optionally zip the model folder for download\n",
        "zip_filename = \"saved_model_tfidf.zip\"\n",
        "shutil.make_archive(base_name=\"saved_model_tfidf\", format=\"zip\", root_dir=save_dir)\n",
        "print(f\"Model and vectorizer saved to {save_dir} and zipped as {zip_filename}\")\n",
        "\n",
        "if _IN_COLAB:\n",
        "    print(\"Starting download of the zip (Colab)...\")\n",
        "    colab_files.download(zip_filename)"
      ],
      "metadata": {
        "id": "OpAV-7fKmlcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1ï¸âƒ£1ï¸âƒ£ EVALUATION / TESTING\n",
        "# =========================\n",
        "print(\"\\nStarting evaluation on test set...\")\n",
        "\n",
        "# Predict labels\n",
        "y_pred = multi_clf.predict(X_test_tfidf)  # shape (n_samples, n_outputs)\n",
        "\n",
        "# For probabilities per aspect (for mAP) â€” ensure estimator supports predict_proba\n",
        "probas_per_aspect = []\n",
        "for i, est in enumerate(multi_clf.estimators_):\n",
        "    if hasattr(est, \"predict_proba\"):\n",
        "        probas = est.predict_proba(X_test_tfidf)  # shape (n_samples, n_classes_for_aspect)\n",
        "    else:\n",
        "        # fallback: use decision_function and convert to pseudo-prob via softmax\n",
        "        try:\n",
        "            dec = est.decision_function(X_test_tfidf)\n",
        "            # if binary, shape (n_samples,) -> expand\n",
        "            if dec.ndim == 1:\n",
        "                dec = np.vstack([-dec, dec]).T\n",
        "            # softmax\n",
        "            exp = np.exp(dec - np.max(dec, axis=1, keepdims=True))\n",
        "            probas = exp / np.sum(exp, axis=1, keepdims=True)\n",
        "        except Exception:\n",
        "            # fall back to one-hot of predicted label\n",
        "            preds = est.predict(X_test_tfidf)\n",
        "            n_classes = len(np.unique(np.concatenate([y_train[:, i], y_test[:, i]])))\n",
        "            probas = np.zeros((X_test_tfidf.shape[0], n_classes))\n",
        "            for idx, p in enumerate(preds):\n",
        "                # find index of class in est.classes_\n",
        "                try:\n",
        "                    class_idx = list(est.classes_).index(p)\n",
        "                    probas[idx, class_idx] = 1.0\n",
        "                except ValueError:\n",
        "                    pass\n",
        "    probas_per_aspect.append(probas)\n",
        "\n",
        "# Compute metrics per aspect\n",
        "metrics = []\n",
        "for i, aspect in enumerate(aspect_names):\n",
        "    y_true = y_test[:, i]\n",
        "    y_pr = y_pred[:, i]\n",
        "    y_prob = probas_per_aspect[i]  # shape (n_samples, n_classes_aspect)\n",
        "\n",
        "    acc  = accuracy_score(y_true, y_pr)\n",
        "    prec = precision_score(y_true, y_pr, average='macro', zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pr, average='macro', zero_division=0)\n",
        "    f1   = f1_score(y_true, y_pr, average='macro', zero_division=0)\n",
        "\n",
        "    # mAP: we need y_true in one-hot and y_prob aligned to same classes\n",
        "    classes = multi_clf.estimators_[i].classes_\n",
        "    # Binarize y_true to shape (n_samples, n_classes)\n",
        "    y_true_bin = label_binarize(y_true, classes=classes)\n",
        "    # If only one class in classes, average_precision_score will fail; handle it\n",
        "    try:\n",
        "        mAP = average_precision_score(y_true_bin, y_prob, average='macro')\n",
        "    except Exception:\n",
        "        mAP = 0.0\n",
        "\n",
        "    metrics.append({\n",
        "        \"Aspect\": aspect,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1\": f1,\n",
        "        \"mAP\": mAP,\n",
        "        \"Classes\": classes.tolist()\n",
        "    })\n",
        "\n",
        "# Save metrics to file and print\n",
        "results_dir = \"results\"\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "results_path = os.path.join(results_dir, \"evaluation_results.txt\")\n",
        "\n",
        "with open(results_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"ğŸ“Š Evaluation Results\\n\")\n",
        "    f.write(\"=\" * 60 + \"\\n\")\n",
        "    for m in metrics:\n",
        "        f.write(f\"{m['Aspect']}\\n\")\n",
        "        f.write(f\"  Classes: {m['Classes']}\\n\")\n",
        "        f.write(f\"  Accuracy: {m['Accuracy']:.4f}\\n\")\n",
        "        f.write(f\"  Precision (macro): {m['Precision']:.4f}\\n\")\n",
        "        f.write(f\"  Recall (macro): {m['Recall']:.4f}\\n\")\n",
        "        f.write(f\"  F1 (macro): {m['F1']:.4f}\\n\")\n",
        "        f.write(f\"  mAP: {m['mAP']:.4f}\\n\")\n",
        "        f.write(\"-\" * 60 + \"\\n\")\n",
        "\n",
        "    mean_f1 = np.mean([m['F1'] for m in metrics])\n",
        "    mean_map = np.mean([m['mAP'] for m in metrics])\n",
        "    f.write(f\"\\nOverall Mean F1: {mean_f1:.4f}\\n\")\n",
        "    f.write(f\"Overall Mean mAP: {mean_map:.4f}\\n\")\n",
        "\n",
        "print(\"Evaluation results written to:\", results_path)\n",
        "print(\"\\nPer-aspect metrics:\")\n",
        "pprint(metrics)\n",
        "\n",
        "if _IN_COLAB:\n",
        "    colab_files.download(results_path)\n",
        "\n",
        "# Also save a CSV summary\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "metrics_df.to_csv(os.path.join(results_dir, \"evaluation_results.csv\"), index=False)\n",
        "\n",
        "# Save confusion matrices and classification reports for deeper inspection\n",
        "for i, aspect in enumerate(aspect_names):\n",
        "    cm = confusion_matrix(y_test[:, i], y_pred[:, i], labels=multi_clf.estimators_[i].classes_)\n",
        "    cr = classification_report(y_test[:, i], y_pred[:, i], zero_division=0)\n",
        "    np.savetxt(os.path.join(results_dir, f\"confusion_matrix_{aspect}.csv\"), cm, delimiter=\",\", fmt='%d')\n",
        "    with open(os.path.join(results_dir, f\"class_report_{aspect}.txt\"), \"w\", encoding='utf-8') as f:\n",
        "        f.write(cr)\n",
        "\n",
        "# Zip results (optional)\n",
        "shutil.make_archive(\"results\", 'zip', results_dir)\n",
        "if _IN_COLAB:\n",
        "    colab_files.download(\"results.zip\")\n"
      ],
      "metadata": {
        "id": "KHNLTVFKmofe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1ï¸âƒ£2ï¸âƒ£ HOW TO USE THE MODEL LOCALLY (INFERENCE EXAMPLES)\n",
        "# =========================\n",
        "print(\"\\nâœ… To use the saved model locally (after download), reload as follows:\")\n",
        "\n",
        "usage_example = \"\"\"\n",
        "# Example usage after downloading saved_model_tfidf.zip and extracting:\n",
        "import joblib\n",
        "model = joblib.load(\"saved_model_tfidf/multioutput_model.joblib\")\n",
        "vectorizer = joblib.load(\"saved_model_tfidf/vectorizer.joblib\")\n",
        "\n",
        "def predict_review(review_text):\n",
        "    # normalize like training\n",
        "    review_text_norm = normalize_arabic(review_text)\n",
        "    X = vectorizer.transform([review_text_norm])\n",
        "    preds = model.predict(X)[0]  # array of 5 labels\n",
        "    return dict(zip({0}, preds))\n",
        "\n",
        "# Example:\n",
        "print(predict_review(\"Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ù…Ø±ØªÙØ¹Ø© Ù„ÙƒÙ† Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ Ù…Ù…ØªØ§Ø²ÙˆÙ†\"))\n",
        "\"\"\".format(aspect_names)\n",
        "\n",
        "print(usage_example)\n",
        "print(\"âœ… Pipeline complete. Good luck testing on Colab! If you want, I can now:\")\n",
        "print(\"  â€¢ convert this to a ready-to-download .ipynb file,\")\n",
        "print(\"  â€¢ or swap LogisticRegression for RandomForest/SVC or add AraBERT hybrid features,\")\n",
        "print(\"  â€¢ or add cross-validation and hyperparameter search (GridSearchCV / RandomizedSearchCV).\")\n"
      ],
      "metadata": {
        "id": "nPbo9-uwmqSP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}